import xml.etree.ElementTree as ET
import re
import pandas as pd
import numpy as np

def get_route_type(trip_id):
    """Helper function to categorize trips based on their ID prefix."""
    if 'main' in trip_id:
        return 'Mainline'
    elif 'on_ramp' in trip_id:
        return 'On-Ramp'
    elif 'off_ramp' in trip_id:
        return 'Off-Ramp'
    return 'Other'


def parse_tripinfo_for_episode_stats(tripinfo_path):
    """
    Parses a tripinfo.xml file from a single episode and calculates
    both overall and per-route-type aggregate statistics.

    Args:
        tripinfo_path (str): The path to the tripinfo.xml file.

    Returns:
        dict: A dictionary of aggregated metrics for the episode.
    """
    try:
        tree = ET.parse(tripinfo_path)
        root = tree.getroot()
    except (FileNotFoundError, ET.ParseError):
        print(f"Warning: Could not parse tripinfo file at {tripinfo_path}")
        return {}

    trip_data = []
    for trip in root.findall('tripinfo'):
        # Only process trips that have a duration (i.e., they completed)
        if trip.get('duration'):
            trip_attrs = trip.attrib
            # Add route type for per-route analysis
            trip_attrs['route_type'] = get_route_type(trip_attrs['id'])
            # Convert numeric attributes to float
            for key, val in trip_attrs.items():
                try:
                    trip_attrs[key] = float(val)
                except (ValueError, TypeError):
                    continue
            trip_attrs['vaporized'] = 1 if 'vaporized' in trip.keys() else 0
            trip_data.append(trip_attrs)

    if not trip_data:
        return {'total_throughput': 0}

    df = pd.DataFrame(trip_data)
    df['timeLoss_sq'] = df['timeLoss']**2

    # --- Overall Aggregations ---
    overall_stats = {
        'total_throughput': len(df),
        'total_travel_time': df['duration'].sum(),
        'avg_travel_time': df['duration'].mean(),
        'total_time_loss': df['timeLoss'].sum(),
        'avg_time_loss': df['timeLoss'].mean(),
        'sum_of_squared_time_loss': df['timeLoss_sq'].sum(),
        'total_waiting_time': df['waitingTime'].sum(),
        'avg_waiting_time': df['waitingTime'].mean(),
        'num_teleported_tripinfo': df['vaporized'].sum()
    }

    # --- Per-Route Aggregations ---
    route_stats = df.groupby('route_type').agg(
        avg_time_loss=('timeLoss', 'mean'),
        avg_travel_time=('duration', 'mean'),
        throughput=('id', 'count')
    ).rename(columns=lambda x: x.replace(" ", "_")).unstack()

    # Flatten the multi-index from the unstack and create clean column names
    route_stats.index = [f"{col[1]}_{col[0]}" for col in route_stats.index]
    route_stats_dict = route_stats.to_dict()

    # Combine all stats and return
    return {**overall_stats, **route_stats_dict}


def parse_sumo_log(log_path):
    """
    Parses a SUMO log file to extract vehicle insertion and performance data.
    """
    # (This function remains the same as the previous response)
    try:
        with open(log_path, 'r') as f:
            content = f.read()
    except FileNotFoundError:
        return {}

    inserted_loaded_match = re.search(r'Vehicles:\s*\n\s*Inserted:\s*(\d+)\s*\(Loaded:\s*(\d+)\)', content)
    emergency_stops_match = re.search(r'Emergency Stops:\s*(\d+)', content)
    
    demand_inserted = int(inserted_loaded_match.group(1)) if inserted_loaded_match else 0
    demand_loaded = int(inserted_loaded_match.group(2)) if inserted_loaded_match else 0
    
    return {
        'demand_loaded': demand_loaded,
        'demand_inserted': demand_inserted,
        'service_rate': demand_inserted / demand_loaded if demand_loaded > 0 else 0,
        'num_emergency_stops': int(emergency_stops_match.group(1)) if emergency_stops_match else 0
    }

def parse_framework_log(log_path):
    """
    Parses the CSV log generated by the framework (play.py/observe.py).
    """
    # (This function is simplified from the last response, as we get scenario info from sumo_env now)
    try:
        df = pd.read_csv(log_path)
        # Calculate average of key detector metrics over the episode
        return {
            'avg_ramp_queue_veh': df['ramp_queue_veh'].mean(),
            'avg_downstream_speed_kmh': df['mainline_speed_downstream_km/h'].mean(),
            'avg_merge_area_occ_percent': df['mainline_occ_mergeArea_percent'].mean()
        }
    except (FileNotFoundError, pd.errors.EmptyDataError):
        return {}